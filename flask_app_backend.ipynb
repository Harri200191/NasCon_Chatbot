{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS  \n",
    "import speech_recognition as sr\n",
    "import urllib\n",
    "from utils import * \n",
    "import requests\n",
    "import together\n",
    "import json\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made the server live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'value': '1ba43194c3833eb9cd86a29236dedfb6120789f28eb1c29109c77824add2787c-089c3033879467bc304426e625951a44ebecf022bb3b405c519aaf89911ca475'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_name = 'harisrehman195103@gmail.com/llama-2-7b-chat-law-2024-03-02-15-00-52'\n",
    "base_model_name = \"togethercomputer/llama-2-7b-chat\" \n",
    "together.Models.start(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
       "  '_id': '65e349d707d57fd92ca0c37b',\n",
       "  'name': 'harisrehman195103@gmail.com/llama-2-7b-chat-law-2024-03-02-15-00-52',\n",
       "  'display_type': 'chat',\n",
       "  'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters',\n",
       "  'creator_organization': 'harisrehman195103@gmail.com',\n",
       "  'hardware_label': 'L40',\n",
       "  'num_parameters': '6738415616',\n",
       "  'release_date': '2024-03-02T15:46:31.235Z',\n",
       "  'show_in_playground': True,\n",
       "  'owner': 'harisrehman195103@gmail.com',\n",
       "  'owner_address': '0x75b8672cb99aa4456064dc1725ca235012fc6907',\n",
       "  'owner_userid': '65e2c8f5d14c747cee2d3e16',\n",
       "  'parent': 'togethercomputer/llama-2-7b-chat',\n",
       "  'base': 'togethercomputer/llama-2-7b-chat',\n",
       "  'path': 'r2://together-dev/finetune/65e2c8f5d14c747cee2d3e16/harisrehman195103@gmail.com/llama-2-7b-chat-law-2024-03-02-15-00-52/ft-1739a3ac-6d52-4c95-ab88-1dcdd53bb4ce-2024-03-02-07-42-02',\n",
       "  'files': [{'filename': 'added_tokens.json',\n",
       "    'size': 21,\n",
       "    'hash': 'ddfe5408fa8791d2ce96f5aeeb2bb76',\n",
       "    'modified': '2024-03-02T15:42:06.266Z'},\n",
       "   {'filename': 'config.json',\n",
       "    'size': 658,\n",
       "    'hash': '67ffcadf5af9ba96ff850c6c6b546c6',\n",
       "    'modified': '2024-03-02T15:42:05.712Z'},\n",
       "   {'filename': 'generation_config.json',\n",
       "    'size': 132,\n",
       "    'hash': 'b655e018b2680db71f35cbdae6c0802',\n",
       "    'modified': '2024-03-02T15:42:06.548Z'},\n",
       "   {'filename': 'model-00001-of-00003.safetensors',\n",
       "    'size': 4938985248,\n",
       "    'hash': '37de3313b24632c01281d904d11c73c1-58',\n",
       "    'modified': '2024-03-02T15:44:22.559Z'},\n",
       "   {'filename': 'model-00002-of-00003.safetensors',\n",
       "    'size': 4947390768,\n",
       "    'hash': '84d8e203b120d30264ded62b7f5c51c6-59',\n",
       "    'modified': '2024-03-02T15:44:11.567Z'},\n",
       "   {'filename': 'model-00003-of-00003.safetensors',\n",
       "    'size': 3590488736,\n",
       "    'hash': 'e4b47249da680653b00673ac51aa78f9-42',\n",
       "    'modified': '2024-03-02T15:43:39.518Z'},\n",
       "   {'filename': 'model.safetensors.index.json',\n",
       "    'size': 23950,\n",
       "    'hash': 'ec4e8026d001d56b437cc9bbcaa1f45',\n",
       "    'modified': '2024-03-02T15:42:06.376Z'},\n",
       "   {'filename': 'special_tokens_map.json',\n",
       "    'size': 550,\n",
       "    'hash': '427d75721b0ff3694561b76782ff3f8',\n",
       "    'modified': '2024-03-02T15:42:06.396Z'},\n",
       "   {'filename': 'tokenizer.model',\n",
       "    'size': 499723,\n",
       "    'hash': 'eeec4125e9c7560836b4873b6f8e302',\n",
       "    'modified': '2024-03-02T15:42:08.862Z'},\n",
       "   {'filename': 'tokenizer_config.json',\n",
       "    'size': 1105,\n",
       "    'hash': '27fc6637cf356ec3695c86fef5f63c9',\n",
       "    'modified': '2024-03-02T15:42:06.721Z'}],\n",
       "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
       "   'stop': ['[/INST]', '</s>'],\n",
       "   'chat_template_name': 'llama'},\n",
       "  'worker_config': None,\n",
       "  'worker_template': None,\n",
       "  'pricing': {'hourly': 1400000000,\n",
       "   'input': 0,\n",
       "   'output': 0,\n",
       "   'finetune': 0,\n",
       "   'base': 0},\n",
       "  'created_at': '2024-03-02T15:46:31.424Z',\n",
       "  'update_at': '2024-03-02T15:46:31.424Z',\n",
       "  'autopilot_pool': None,\n",
       "  'has_wandb_telemetry': False,\n",
       "  'wandb_url': '',\n",
       "  'ready': False}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Models.ready(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [02/Mar/2024 22:34:04] \"GET /api/generate-text/hello HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '85e3227bba29d1dc-MCT', 'status': 'finished', 'prompt': ['<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> hello [/INST]'], 'model': 'togethercomputer/llama-2-7b-chat', 'model_owner': '', 'num_returns': 1, 'args': {'model': 'togethercomputer/llama-2-7b-chat', 'prompt': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> hello [/INST]', 'top_p': 0.8, 'top_k': 90, 'temperature': 0.4, 'max_tokens': 512, 'stop': ['</s>', '[/INST]'], 'repetition_penalty': 1.1, 'logprobs': None, 'safety_model': None}, 'subjobs': [], 'output': {'finish_reason': 'eos_token', 'usage': {'prompt_tokens': 33, 'completion_tokens': 146, 'total_tokens': 179}, 'result_type': 'language-model-inference', 'choices': [{'text': \"  Hello there! *adjusts glasses* It's a pleasure to meet you! As a helpful mobile phone expert, I'm here to assist you with any questions or concerns you may have about your phone. Whether you're looking for tips on how to use your phone more efficiently, need help troubleshooting a problem, or want to learn about the latest phone trends and features, I'm here to help.\\n\\nSo, what can I help you with today? Do you have a specific question or topic in mind, or do you just want some general advice on how to get the most out of your phone? Fire away, and I'll do my best to help!\", 'finish_reason': 'eos'}], 'prompt': [{'text': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> hello [/INST]', 'tokens': [], 'token_logprobs': []}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Mar/2024 22:34:08] \"GET /api/generate-text/How%20are%20you HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '85e322bcdb495b0e-VIE', 'status': 'finished', 'prompt': ['<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> How are you [/INST]'], 'model': 'togethercomputer/llama-2-7b-chat', 'model_owner': '', 'num_returns': 1, 'args': {'model': 'togethercomputer/llama-2-7b-chat', 'prompt': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> How are you [/INST]', 'top_p': 0.8, 'top_k': 90, 'temperature': 0.4, 'max_tokens': 512, 'stop': ['</s>', '[/INST]'], 'repetition_penalty': 1.1, 'logprobs': None, 'safety_model': None}, 'subjobs': [], 'output': {'finish_reason': 'eos_token', 'usage': {'prompt_tokens': 35, 'completion_tokens': 162, 'total_tokens': 197}, 'result_type': 'language-model-inference', 'choices': [{'text': \"  Hello there! *adjusts glasses* It's a pleasure to meet you! As a helpful mobile phone expert, I'm here to assist you with any questions or concerns you may have about your phone. Whether you're looking for tips on how to use your phone more efficiently, need help troubleshooting a problem, or want to learn about the latest phone trends and features, I'm here to help! ðŸ“±ðŸ’¡\\n\\nSo, what can I help you with today? Do you have a specific question or topic in mind, or do you just want some general advice on how to get the most out of your phone? Let me know, and I'll do my best to assist you! ðŸ˜Š\", 'finish_reason': 'eos'}], 'prompt': [{'text': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> How are you [/INST]', 'tokens': [], 'token_logprobs': []}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Mar/2024 22:34:20] \"GET /api/generate-text/Tell%20me%20about%20old%20phones HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '85e322e96858d1dc-MCT', 'status': 'finished', 'prompt': ['<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Tell me about old phones [/INST]'], 'model': 'togethercomputer/llama-2-7b-chat', 'model_owner': '', 'num_returns': 1, 'args': {'model': 'togethercomputer/llama-2-7b-chat', 'prompt': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Tell me about old phones [/INST]', 'top_p': 0.8, 'top_k': 90, 'temperature': 0.4, 'max_tokens': 512, 'stop': ['</s>', '[/INST]'], 'repetition_penalty': 1.1, 'logprobs': None, 'safety_model': None}, 'subjobs': [], 'output': {'finish_reason': 'length', 'usage': {'prompt_tokens': 38, 'completion_tokens': 512, 'total_tokens': 550}, 'result_type': 'language-model-inference', 'choices': [{'text': \"  Ah, old phones! *chuckles* Those were the days, weren't they? *wistfully* Yes, I'm a helpful mobile phone expert, and I've seen a lot of phones come and go over the years. *nods*\\n\\nOh, where to start? *thinks* Well, let's see... *scratches chin* Old phones were so much simpler, you know? *smirks* They didn't have all the bells and whistles that modern phones have. *chuckles* No, they were basic, straightforward devices. *nods*\\n\\nRemember those big, bulky Nokia bricks? *grins* Yeah, those were the days! *wistfully* They were so heavy, but they could last forever on a single charge. *chuckles* And the sounds! *exaggeratedly* Oh, the sounds! *clicks tongue* The beeps, the chimes, the ringtone... *sighs* It was like music to our ears! *smirks*\\n\\nAnd don't even get me started on the keypads! *laughs* Oh, those were a nightmare! *chuckles* You had to press the keys just right, or you'd end up with a bunch of typos. *rolls eyes* But hey, at least we didn't have to worry about running out of battery! *winks*\\n\\nAnd then there were the flip phones! *excitedly* Oh, those were the best! *grins* You could flip 'em open and close, and they were so sleek and stylish. *admiringly* They were like little pieces of art! *nods*\\n\\nBut you know what the best thing about old phones was? *smirks* They were reliable! *nods* They never crashed, they never froze, and they never ran out of battery. *chuckles* They just worked! *winks*\\n\\nSo, what do you think? *smiles* Do you miss old phones? *curious* Or are you one of those modern phone enthusiasts? *grins* Either way, I'm here to help! *winks* What can I do for you? *help\", 'finish_reason': 'length'}], 'prompt': [{'text': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Tell me about old phones [/INST]', 'tokens': [], 'token_logprobs': []}]}}\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\")\n",
    " \n",
    "@app.route('/api/generate-text/<string:text>', methods=['GET'])\n",
    "def generate_text(text):\n",
    "\n",
    "    test_chat_prompt = f\"<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> {text} [/INST]\"  \n",
    "\n",
    "    output = together.Complete.create(\n",
    "        prompt = test_chat_prompt,\n",
    "        model = base_model_name,\n",
    "        max_tokens = 512,\n",
    "        temperature = 0.4,\n",
    "        top_k = 90,\n",
    "        top_p = 0.8,\n",
    "        repetition_penalty = 1.1,\n",
    "        stop = ['</s>']\n",
    "    )\n",
    "\n",
    "    txt = output[\"output\"][\"choices\"][0][\"text\"]\n",
    "    print(output)\n",
    "\n",
    "    return jsonify({'text': txt}), 200 \n",
    "\n",
    "@app.route('/api/speech-to-text', methods=['POST']) \n",
    "def record_and_recognize(): \n",
    "    if 'audio_url' not in request.json:\n",
    "        return jsonify({'error': 'No audio URL provided'}), 400\n",
    "\n",
    "    audio_url = request.json['audio_url'] \n",
    "\n",
    "    try: \n",
    "        audio_file_path, _ = urllib.request.urlretrieve(audio_url)\n",
    "        print(audio_file_path)\n",
    " \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_file_path) as source:\n",
    "            audio_data = recognizer.record(source) \n",
    "        recognized_text = recognizer.recognize_google(audio_data)\n",
    "\n",
    "        return jsonify({'text': recognized_text}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Error processing audio: {str(e)}'}), 500\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
