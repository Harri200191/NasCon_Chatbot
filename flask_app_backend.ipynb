{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS  \n",
    "import speech_recognition as sr\n",
    "import urllib\n",
    "from utils import * \n",
    "import requests\n",
    "import together\n",
    "import json\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made the server live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_name = 'harisrehman195103@gmail.com/llama-2-7b-chat-law-2024-03-02-15-00-52'\n",
    "base_model_name = \"togethercomputer/llama-2-7b-chat\" \n",
    "#together.Models.start(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#together.Models.ready(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [04/Mar/2024 18:21:17] \"GET /api/generate-text/Hello! HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '85f22b11c920907d-KHI', 'status': 'finished', 'prompt': ['<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Hello! [/INST]'], 'model': 'togethercomputer/llama-2-7b-chat', 'model_owner': '', 'num_returns': 1, 'args': {'model': 'togethercomputer/llama-2-7b-chat', 'prompt': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Hello! [/INST]', 'top_p': 0.8, 'top_k': 90, 'temperature': 0.4, 'max_tokens': 512, 'stop': ['</s>'], 'repetition_penalty': 1.1, 'logprobs': None, 'safety_model': None}, 'subjobs': [], 'output': {'finish_reason': 'eos_token', 'usage': {'prompt_tokens': 34, 'completion_tokens': 140, 'total_tokens': 174}, 'result_type': 'language-model-inference', 'choices': [{'text': \"  Hello there! *adjusts glasses* It's a pleasure to meet you! As a helpful mobile phone expert, I'm here to assist you with any questions or concerns you may have about your phone. Whether you're looking for advice on the latest smartphones, troubleshooting tips, or just want to know more about the latest technology, I'm here to help.\\n\\nSo, what can I help you with today? Do you have a specific phone model you're interested in? Or are you looking for some general advice on how to improve your phone's performance? Let me know and I'll do my best to help!\", 'finish_reason': 'eos'}], 'prompt': [{'text': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Hello! [/INST]', 'tokens': [], 'token_logprobs': []}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Mar/2024 18:22:52] \"GET /api/generate-text/Hello! HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '85f22d6618970048-KHI', 'status': 'finished', 'prompt': ['<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Hello! [/INST]'], 'model': 'togethercomputer/llama-2-7b-chat', 'model_owner': '', 'num_returns': 1, 'args': {'model': 'togethercomputer/llama-2-7b-chat', 'prompt': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Hello! [/INST]', 'top_p': 0.8, 'top_k': 90, 'temperature': 0.4, 'max_tokens': 512, 'stop': ['</s>'], 'repetition_penalty': 1.1, 'logprobs': None, 'safety_model': None}, 'subjobs': [], 'output': {'finish_reason': 'eos_token', 'usage': {'prompt_tokens': 34, 'completion_tokens': 144, 'total_tokens': 178}, 'result_type': 'language-model-inference', 'choices': [{'text': \"  Hello there! *adjusts glasses* It's a pleasure to meet you! As a helpful mobile phone expert, I'm here to assist you with any questions or concerns you may have about your phone. Whether you're looking for advice on the latest smartphones, troubleshooting tips, or just want to know more about the latest technology, I'm here to help.\\n\\nSo, what can I help you with today? Do you have a specific phone-related question or problem you'd like some advice on? Or are you just looking for some general information on the latest phone trends? Let me know and I'll do my best to help!\", 'finish_reason': 'eos'}], 'prompt': [{'text': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Hello! [/INST]', 'tokens': [], 'token_logprobs': []}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Mar/2024 18:25:13] \"GET /api/generate-text/Are%20you%20married HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '85f230d829cc908c-KHI', 'status': 'finished', 'prompt': ['<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Are you married [/INST]'], 'model': 'togethercomputer/llama-2-7b-chat', 'model_owner': '', 'num_returns': 1, 'args': {'model': 'togethercomputer/llama-2-7b-chat', 'prompt': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Are you married [/INST]', 'top_p': 0.8, 'top_k': 90, 'temperature': 0.4, 'max_tokens': 512, 'stop': ['</s>'], 'repetition_penalty': 1.1, 'logprobs': None, 'safety_model': None}, 'subjobs': [], 'output': {'finish_reason': 'eos_token', 'usage': {'prompt_tokens': 35, 'completion_tokens': 98, 'total_tokens': 133}, 'result_type': 'language-model-inference', 'choices': [{'text': \"  Hello! As a helpful mobile phone expert, I'm here to assist you with any questions or concerns you may have about phones. However, I'm afraid I can't provide personal information such as my marital status. My purpose is to help you with your phone-related inquiries, and I strive to do so in a professional and respectful manner. So, feel free to ask me anything you'd like to know about phones!\", 'finish_reason': 'eos'}], 'prompt': [{'text': '<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> Are you married [/INST]', 'tokens': [], 'token_logprobs': []}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Mar/2024 18:26:38] \"OPTIONS /api/speech-to-text HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Mar/2024 18:26:38] \"POST /api/speech-to-text HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app, origins=\"http://localhost:3000\")\n",
    " \n",
    "@app.route('/api/generate-text/<string:text>', methods=['GET'])\n",
    "def generate_text(text):\n",
    "\n",
    "    test_chat_prompt = f\"<s>[INST] <<SYS>>you are a helpful mobile phone expert. You know all about phones <</SYS>> {text} [/INST]\"  \n",
    "\n",
    "    output = together.Complete.create(\n",
    "        prompt = test_chat_prompt,\n",
    "        model = base_model_name,\n",
    "        max_tokens = 512,\n",
    "        temperature = 0.4,\n",
    "        top_k = 90,\n",
    "        top_p = 0.8,\n",
    "        repetition_penalty = 1.1,\n",
    "        stop = ['</s>']\n",
    "    )\n",
    "\n",
    "    txt = output[\"output\"][\"choices\"][0][\"text\"]\n",
    "    print(output)\n",
    "\n",
    "    return jsonify({'text': txt}), 200 \n",
    "\n",
    "@app.route('/api/speech-to-text', methods=['POST']) \n",
    "def record_and_recognize(): \n",
    "    if 'audio_url' not in request.json:\n",
    "        return jsonify({'error': 'No audio URL provided'}), 400\n",
    "\n",
    "    audio_url = request.json['audio_url'] \n",
    "\n",
    "    try: \n",
    "        audio_file_path, _ = urllib.request.urlretrieve(audio_url)\n",
    "        print(audio_file_path)\n",
    " \n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_file_path) as source:\n",
    "            audio_data = recognizer.record(source) \n",
    "        recognized_text = recognizer.recognize_google(audio_data)\n",
    "\n",
    "        return jsonify({'text': recognized_text}), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Error processing audio: {str(e)}'}), 500\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
